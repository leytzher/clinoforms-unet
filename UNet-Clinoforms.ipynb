{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clinoforms Identification using Image Segmentation (UNet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.utils.data as data\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.nn import functional as F\n",
    "import torch.nn as nn\n",
    "from torch.autograd import Variable\n",
    "import numpy as np\n",
    "import cv2\n",
    "import glob\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import re\n",
    "import os\n",
    "import random\n",
    "from random import randint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sp_noise(image,prob):\n",
    "    '''\n",
    "    Add salt and pepper noise to image\n",
    "    prob: Probability of the noise\n",
    "    '''\n",
    "    output = np.zeros(image.shape,np.uint8)\n",
    "    thres = 1 - prob \n",
    "    for i in range(image.shape[0]):\n",
    "        for j in range(image.shape[1]):\n",
    "            rdn = random.random()\n",
    "            if rdn < prob:\n",
    "                output[i][j] = 0\n",
    "            elif rdn > thres:\n",
    "                output[i][j] = 255\n",
    "            else:\n",
    "                output[i][j] = image[i][j]\n",
    "    return output\n",
    "\n",
    "\n",
    "def gaussian_noise(image):\n",
    "    ''' \n",
    "    Add gaussian noise to image\n",
    "    '''\n",
    "    row, col = image.shape\n",
    "    mean = 0\n",
    "    gauss = np.random.normal(mean,1,(row,col))\n",
    "    gauss = gauss.reshape(row,col)\n",
    "    noisy = image+gauss\n",
    "    return noisy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Extend Dataset abstract class:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SeismicData(data.Dataset):\n",
    "    \"\"\" Load Seismic Dataset.\n",
    "    Args:\n",
    "        image_path(str): the path where the image is located\n",
    "        mask_path(str): the path where the mask is located\n",
    "        option(str): decide which dataset to import\n",
    "    \"\"\"\n",
    "    def __init__(self, image_path, mask_path):\n",
    "        self.image_path = image_path\n",
    "        self.mask_path = mask_path\n",
    "        self.mask_arr = glob.glob(str(mask_path)+\"/*\")\n",
    "        self.image_arr = glob.glob(str(image_path)+str(\"/*\"))\n",
    "        self.data_len = len(self.mask_arr)\n",
    "        \n",
    "    def __getitem__(self, index):\n",
    "        \"\"\"Get specific data corresponding to the index\n",
    "        Args:\n",
    "            index: index of the data\n",
    "        Returns:\n",
    "            Tensor: specific data on index which is converted to Tensor\n",
    "        \"\"\"\n",
    "        single_image_name = self.image_arr[index]\n",
    "        \n",
    "        imgID = fname = re.findall(\"Line\\d+\",single_image_name)[0]\n",
    "        single_mask_name = os.path.join(self.mask_path, f\"{imgID}_mask.png\")\n",
    "        \n",
    "        # Read image and mask\n",
    "        img = cv2.imread(single_image_name)\n",
    "        mask = cv2.imread(single_mask_name)\n",
    "        \n",
    "        # convert image and mask to grayscale\n",
    "        img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "        mask = cv2.cvtColor(mask, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "        # Resize to 256*1216 for U-net\n",
    "        img = img[:,:1216]\n",
    "        mask = mask[:,:1216]\n",
    "        \n",
    "        # Normalize mask to 0 and 1\n",
    "        mask = mask/255\n",
    "#         plt.imshow(img)\n",
    "#         plt.show()\n",
    "#         plt.imshow(mask)\n",
    "#         plt.show()\n",
    "        \n",
    "        # Data augmentation on sampling\n",
    "        ## Image flip\n",
    "        if randint(0,1) == 1:\n",
    "            # we flip horizontally the image and its mask\n",
    "            img = cv2.flip(img,1)\n",
    "            mask = cv2.flip(mask,1)\n",
    "        \n",
    "        addNoise = randint(0,2)\n",
    "        if addNoise == 1:  ## Add some gaussian noise\n",
    "            img = gaussian_noise(img)\n",
    "        elif addNoise == 2:  # Add salt/pepper noise\n",
    "            img = sp_noise(img,0.05)\n",
    "                 \n",
    "        \n",
    "        img_as_tensor = torch.from_numpy(img).int()\n",
    "        mask_as_tensor = torch.from_numpy(mask).int()\n",
    "        \n",
    "        # Reshape to (ch,h,w)\n",
    "        img_as_tensor = torch.reshape(img_as_tensor,(1,img_as_tensor.shape[0],img_as_tensor.shape[1]))\n",
    "        mask_as_tensor = torch.reshape(mask_as_tensor,(1,mask_as_tensor.shape[0],mask_as_tensor.shape[1]))\n",
    "        \n",
    "        # Reshape\n",
    "        \n",
    "#         plt.imshow(img)\n",
    "#         plt.show()\n",
    "#         plt.imshow(mask)\n",
    "#         plt.show()\n",
    "        return (img_as_tensor, mask_as_tensor)\n",
    "        \n",
    "    def __len__(self):\n",
    "        return self.data_len   \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define train and test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = SeismicData(image_path='./seismic/train/images/', mask_path='./seismic/train/masks/')\n",
    "test_dataset = SeismicData(image_path='./seismic/test/images/', mask_path='./seismic/test/masks/')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create data loaders. We will have data augmentation on sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_load = DataLoader(dataset=train_dataset, batch_size=5, shuffle=True)\n",
    "test_data_load = DataLoader(dataset=test_dataset, batch_size=1, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build Model (U-net)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Define loss function (Jaccard's loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def jaccard_loss(true, logits, eps=1e-7):\n",
    "    \"\"\"Computes the Jaccard loss, a.k.a the IoU loss.\n",
    "    Note that PyTorch optimizers minimize a loss. In this\n",
    "    case, we would like to maximize the jaccard loss so we\n",
    "    return the negated jaccard loss.\n",
    "    Args:\n",
    "        true: a tensor of shape [B, H, W] or [B, 1, H, W].\n",
    "        logits: a tensor of shape [B, C, H, W]. Corresponds to\n",
    "            the raw output or logits of the model.\n",
    "        eps: added to the denominator for numerical stability.\n",
    "    Returns:\n",
    "        jacc_loss: the Jaccard loss.\n",
    "    \"\"\"\n",
    "    num_classes = logits.shape[1]\n",
    "    if num_classes == 1:\n",
    "        true_1_hot = torch.eye(num_classes + 1)[true.squeeze(1)]\n",
    "        true_1_hot = true_1_hot.permute(0, 3, 1, 2).float()\n",
    "        true_1_hot_f = true_1_hot[:, 0:1, :, :]\n",
    "        true_1_hot_s = true_1_hot[:, 1:2, :, :]\n",
    "        true_1_hot = torch.cat([true_1_hot_s, true_1_hot_f], dim=1)\n",
    "        pos_prob = torch.sigmoid(logits)\n",
    "        neg_prob = 1 - pos_prob\n",
    "        probas = torch.cat([pos_prob, neg_prob], dim=1)\n",
    "    else:\n",
    "        true_1_hot = torch.eye(num_classes)[true.squeeze(1)]\n",
    "        true_1_hot = true_1_hot.permute(0, 3, 1, 2).float()\n",
    "        probas = F.softmax(probas, dim=1)\n",
    "    true_1_hot = true_1_hot.type(logits.type())\n",
    "    dims = (0,) + tuple(range(2, true.ndimension()))\n",
    "    intersection = torch.sum(probas * true_1_hot, dims)\n",
    "    cardinality = torch.sum(probas + true_1_hot, dims)\n",
    "    union = cardinality - intersection\n",
    "    jacc_loss = (intersection / (union + eps)).mean()\n",
    "    return (1 - jacc_loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Build Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class U_net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(U_net, self).__init__()\n",
    "        \n",
    "        ### Start downward path:\n",
    "        # Conv Block 1 - Down 1\n",
    "        self.conv1_block = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=1, out_channels=32, kernel_size=3, padding=1, stride=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(in_channels=32, out_channels=32, kernel_size=3, padding=1, stride=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "        )\n",
    "        self.max1 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        \n",
    "        # Conv Block 2 - Down 2\n",
    "        self.conv2_block = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=32, out_channels=64, kernel_size=3, padding=1, stride=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(in_channels=64, out_channels=64, kernel_size=3, padding=1, stride=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "        )\n",
    "        self.max2 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        \n",
    "        # Conv Block 3 - Down 3\n",
    "        self.conv3_block = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=64, out_channels=128, kernel_size=3, padding=1, stride=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(in_channels=128, out_channels=128, kernel_size=3, padding=1, stride=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "        )\n",
    "        self.max3 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "\n",
    "        # Conv Block 4 - Down 4\n",
    "        self.conv4_block = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=128, out_channels=256, kernel_size=3, padding=1, stride=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(in_channels=256, out_channels=256, kernel_size=3, padding=1, stride=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "        )\n",
    "        self.max4 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "\n",
    "         # Conv Block 5 - Down 5 ((Bottom of the network))\n",
    "        self.conv5_block = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=256, out_channels=512, kernel_size=3, padding=1, stride=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(in_channels=512, out_channels=512, kernel_size=3, padding=1, stride=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "        )\n",
    "        \n",
    "        ## Start upwards path\n",
    "        \n",
    "        # Up 1\n",
    "        self.up_1 = nn.ConvTranspose2d(in_channels=512, out_channels=256, kernel_size=2, stride=2)\n",
    "        \n",
    "        # Upconvolution Block 1\n",
    "        self.conv_up_1 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=512, out_channels=256, kernel_size=3, padding=1, stride=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(in_channels=256, out_channels=256, kernel_size=3, padding=1, stride=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "        )\n",
    "        \n",
    "        # Up 2\n",
    "        self.up_2 = nn.ConvTranspose2d(in_channels=256, out_channels=128, kernel_size=2, stride=2)\n",
    "        \n",
    "        # Upconvolution Block 2\n",
    "        self.conv_up_2 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=256, out_channels=128, kernel_size=3, padding=1, stride=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(in_channels=128, out_channels=128, kernel_size=3, padding=1, stride=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "        )\n",
    "\n",
    "        # Up 3\n",
    "        self.up_3 = nn.ConvTranspose2d(in_channels=128, out_channels=64, kernel_size=2, stride=2)\n",
    "        \n",
    "        # Upconvolution Block 3\n",
    "        self.conv_up_3 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=128, out_channels=64, kernel_size=3, padding=1, stride=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(in_channels=64, out_channels=64, kernel_size=3, padding=1, stride=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "        )\n",
    "        \n",
    "        # Up 4\n",
    "        self.up_4 = nn.ConvTranspose2d(in_channels=64, out_channels=32, kernel_size=2, stride=2)\n",
    "        \n",
    "        # Upconvolution Block 4\n",
    "        self.conv_up_4 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=64, out_channels=32, kernel_size=3, padding=1, stride=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(in_channels=32, out_channels=32, kernel_size=3, padding=1, stride=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "        )\n",
    "\n",
    "        # Final output\n",
    "        self.conv_final = nn.Conv2d(in_channels=32, out_channels=2, kernel_size=1, padding=0, stride=1)\n",
    "        \n",
    "    def forward(self,x):\n",
    "        #print('input', x.shape)\n",
    "        # Conv1 block (Down)\n",
    "        x = self.conv1_block(x)\n",
    "        #print('after conv1', x.shape)\n",
    "        # Save output for future concatenation\n",
    "        conv1_out = x\n",
    "        conv1_dim_h = x.shape[2]\n",
    "        conv1_dim_w = x.shape[3]\n",
    "        # Max pooling\n",
    "        x = self.max1(x)\n",
    "        #print('before conv2', x.shape)\n",
    "        \n",
    "        # Conv2 block (Down)\n",
    "        x = self.conv2_block(x)\n",
    "        #print('after conv2', x.shape)\n",
    "        # Save output for future concatenation\n",
    "        conv2_out = x\n",
    "        conv2_dim_h = x.shape[2]\n",
    "        conv2_dim_w = x.shape[3]\n",
    "        # Max pooling\n",
    "        x = self.max2(x)\n",
    "        #print('before conv3', x.shape)\n",
    "\n",
    "        # Conv3 block (Down)\n",
    "        x = self.conv3_block(x)\n",
    "        #print('after conv3', x.shape)\n",
    "        # Save output for future concatenation\n",
    "        conv3_out = x\n",
    "        conv3_dim_h = x.shape[2]\n",
    "        conv3_dim_w = x.shape[3]\n",
    "        # Max pooling\n",
    "        x = self.max3(x)\n",
    "        #print('before conv4', x.shape)\n",
    "\n",
    "         # Conv4 block (Down)\n",
    "        x = self.conv4_block(x)\n",
    "        #print('after conv5', x.shape)\n",
    "        # Save output for future concatenation\n",
    "        conv4_out = x\n",
    "        conv4_dim_h = x.shape[2]\n",
    "        conv4_dim_w = x.shape[3]\n",
    "        # Max pooling\n",
    "        x = self.max4(x)\n",
    "        #print('before conv6', x.shape)\n",
    "        \n",
    "        # Bottom of the network\n",
    "        x = self.conv5_block(x)\n",
    "        #print(\"At bottom of the network\",x.shape)\n",
    "        \n",
    "        # Conv1 block (Up)\n",
    "        x = self.up_1(x)\n",
    "        #print('up_1', x.shape)\n",
    "        lower_h = int((conv4_dim_h - x.shape[2])/2)\n",
    "        upper_h = int((conv4_dim_h - lower_h))\n",
    "        lower_w = int((conv4_dim_w - x.shape[3])/2)\n",
    "        upper_w = int((conv4_dim_w - lower_w))\n",
    "        conv4_out_modified = conv4_out[:,:,lower_h:upper_h,lower_w:upper_w]\n",
    "        #print(\"Shape of conv4-out-mod\",conv4_out_modified.shape)\n",
    "        x = torch.cat([x,conv4_out_modified], dim=1)\n",
    "        #print('after cat_1', x.shape)\n",
    "        x = self.conv_up_1(x)\n",
    "        #print('after conv_1', x.shape)\n",
    "\n",
    "        # Conv2 block (Up)\n",
    "        x = self.up_2(x)\n",
    "        #print('up_2', x.shape)\n",
    "        lower_h = int((conv3_dim_h - x.shape[2])/2)\n",
    "        upper_h = int((conv3_dim_h - lower_h))\n",
    "        lower_w = int((conv3_dim_w - x.shape[3])/2)\n",
    "        upper_w = int((conv3_dim_w - lower_w))\n",
    "        conv3_out_modified = conv3_out[:,:,lower_h:upper_h,lower_w:upper_w]\n",
    "        #print(\"Shape of conv3-out-mod\",conv3_out_modified.shape)\n",
    "        x = torch.cat([x,conv3_out_modified], dim=1)\n",
    "        #print('after cat_2', x.shape)\n",
    "        x = self.conv_up_2(x)\n",
    "        #print('after conv_2', x.shape)\n",
    "        \n",
    "        # Conv3 block (Up)\n",
    "        x = self.up_3(x)\n",
    "        #print('up_3', x.shape)\n",
    "        lower_h = int((conv2_dim_h - x.shape[2])/2)\n",
    "        upper_h = int((conv2_dim_h - lower_h))\n",
    "        lower_w = int((conv2_dim_w - x.shape[3])/2)\n",
    "        upper_w = int((conv2_dim_w - lower_w))\n",
    "        conv2_out_modified = conv2_out[:,:,lower_h:upper_h,lower_w:upper_w]\n",
    "        x = torch.cat([x,conv2_out_modified], dim=1)\n",
    "        #print('after cat_3', x.shape)\n",
    "        x = self.conv_up_3(x)\n",
    "        #print('after conv_3', x.shape)\n",
    "        \n",
    "        # Conv4 block (Up)\n",
    "        x = self.up_4(x)\n",
    "        #print('up_4', x.shape)\n",
    "        lower_h = int((conv1_dim_h - x.shape[2])/2)\n",
    "        upper_h = int((conv1_dim_h - lower_h))\n",
    "        lower_w = int((conv1_dim_w - x.shape[3])/2)\n",
    "        upper_w = int((conv1_dim_w - lower_w))\n",
    "        conv1_out_modified = conv1_out[:,:,lower_h:upper_h,lower_w:upper_w]\n",
    "        x = torch.cat([x,conv1_out_modified], dim=1)\n",
    "        #print('after cat_4', x.shape)\n",
    "        x = self.conv_up_4(x)\n",
    "        #print('after conv_4', x.shape)\n",
    "               \n",
    "        # Final \n",
    "        x = self.conv_final(x)\n",
    "        #print('after final', x.shape)\n",
    "        \n",
    "        return x\n",
    "        \n",
    "\n",
    "   \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load model\n",
    "model = U_net()\n",
    "model = torch.nn.DataParallel(model, device_ids=list(range(torch.cuda.device_count()))).cuda()\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.RMSprop(model.module.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for epoch in range(2):\n",
    "    running_loss = 0.0\n",
    "    for i, data in enumerate(train_data_load,0):\n",
    "        inputs, labels = data\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        outputs = model(inputs.float())\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        print(outputs.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
